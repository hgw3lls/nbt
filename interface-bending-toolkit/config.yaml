# Which backend to use: "openai" or "hf_local"
provider: openai

# Default profile name (can be overridden with --profile)
profile: default

openai:
  model: gpt-4.1-mini
  max_tokens: 512
  api_key_env: OPENAI_API_KEY

hf_local:
  model_name: gpt2
  max_new_tokens: 256
  device: cpu
  temperature: 1.0

profiles:
  default:
    # global defaults
    temperature: 1.0
    max_tokens: 512

  clean:
    temperature: 0.4
    max_tokens: 512
    entropy_seed_runs: 3
    prompt_recursion_steps: 3
    jitter_min_delay: 0.01
    jitter_max_delay: 0.06

  noisy:
    temperature: 1.3
    max_tokens: 512
    entropy_seed_runs: 8
    prompt_recursion_steps: 6
    jitter_min_delay: 0.02
    jitter_max_delay: 0.30

